from dotenv import load_dotenv
import os
import re
from mistralai import Mistral
from mistralai.models import OCRResponse
from openai import OpenAI
import tiktoken  # OpenAIã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from tqdm import tqdm  # é€²æ—ãƒãƒ¼ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª


# ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’å–å¾—
enc = tiktoken.encoding_for_model("gpt-4o-mini")


def ocr_pdf(api_key, file_name, data_dir):
    if not api_key:
        raise ValueError("MISTRAL_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # Mistral APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ä½œæˆ
    client = Mistral(api_key=api_key)


    pdf_path = f"{data_dir}/{file_name}"

    # PDFã‚’Mistralã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_pdf = client.files.upload(
        file={
            "file_name": file_name,
            "content": open(pdf_path, "rb"),
        },
        purpose="ocr"
    )

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸPDFã®ã‚µã‚¤ãƒ³ä»˜ãURLã‚’å–å¾—
    signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)

    # OCRå‡¦ç†ã‚’å®Ÿè¡Œ
    ocr_response = client.ocr.process(
        model="mistral-ocr-latest",
        document={
            "type": "document_url",
            "document_url": signed_url.url,
        },
        include_image_base64=True
    )
    return ocr_response

def save_markdown(content, filename="output.md"):
    """ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®å†…å®¹ã‚’æŒ‡å®šã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"""
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"Markdown saved to {filename}")


def replace_images_in_markdown(markdown_str: str, images_dict: dict) -> str:
    for img_name, base64_str in images_dict.items():
        markdown_str = markdown_str.replace(f"![{img_name}]({img_name})", f"![{img_name}]({base64_str})")
    return markdown_str

def get_combined_markdown(ocr_response: OCRResponse) -> str:
  markdowns: list[str] = []
  for page in ocr_response.pages:
    image_data = {}
    for img in page.images:
      image_data[img.id] = img.image_base64
    markdowns.append(replace_images_in_markdown(page.markdown, image_data))
  return "\n\n".join(markdowns)

def split_title_and_reference(content):
    """æœ€åˆã® `#` ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã€`# References` éƒ¨åˆ†ã®ã¿ã‚’å‚è€ƒæ–‡çŒ®ã¨ã—ã¦åˆ†é›¢ã—ã€ãã‚Œä»¥é™ã¯æœ¬æ–‡ã¨ã—ã¦æ‰±ã†"""
    lines = content.split("\n")

    title = None
    reference = None
    body_start = 0
    reference_start = None
    next_header_after_reference = None

    # æœ€åˆã® `# ` ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã™ã‚‹
    for i, line in enumerate(lines):
        if line.startswith("# "):  # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚¿ã‚¤ãƒˆãƒ«
            title = line.strip()
            body_start = i + 1  # ã‚¿ã‚¤ãƒˆãƒ«ã®æ¬¡ã®è¡Œã‹ã‚‰æœ¬æ–‡é–‹å§‹
            break

    # `# References` ä»¥é™ã‚’å‚è€ƒæ–‡çŒ®ã¨ã—ã¦æ‰±ã†
    for i, line in enumerate(lines):
        if re.match(r"^#{1,2} References", line, re.IGNORECASE):  # `# References` ã¾ãŸã¯ `## References`
            reference_start = i
            break

    # `# References` ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€ãã®å¾Œã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¢ã™
    if reference_start is not None:
        for i in range(reference_start + 1, len(lines)):
            if re.match(r"^#{1,6} ", lines[i]):  # æ¬¡ã®ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆ`#`, `##`, `###` ...ï¼‰
                next_header_after_reference = i
                break

    # æœ¬æ–‡ã®å–å¾—
    if reference_start is not None:
        body = "\n".join(lines[body_start:reference_start]).strip()  # `# References` ã‚ˆã‚Šå‰ã¯æœ¬æ–‡
        reference = "\n".join(lines[reference_start:next_header_after_reference]).strip() if next_header_after_reference else "\n".join(lines[reference_start:]).strip()
        body += "\n\n" + "\n".join(lines[next_header_after_reference:]).strip() if next_header_after_reference else ""  # `# References` ä»¥é™ã®æ–°ã—ã„ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚ã‚Œã°æœ¬æ–‡ã«è¿½åŠ 
    else:
        body = "\n".join(lines[body_start:]).strip()  # å‚è€ƒæ–‡çŒ®ãŒãªã„å ´åˆã¯ã™ã¹ã¦æœ¬æ–‡
        reference = None

    return title, body, reference


def split_by_headings(content, max_tokens=8000):
    """è¦‹å‡ºã—ã”ã¨ã«ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ†å‰²ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’èª¿æ•´"""
    sections = re.split(r"(^# .+?$)", content, flags=re.MULTILINE)  # è¦‹å‡ºã—ã§åˆ†å‰²
    chunks = []
    current_chunk = ""

    for i in range(len(sections)):
        section = sections[i].strip()
        if not section:
            continue

        section_tokens = len(enc.encode(section))

        # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¶…ãˆãŸå ´åˆã€æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é–‹å§‹
        if len(enc.encode(current_chunk)) + section_tokens > max_tokens:
            chunks.append(current_chunk.strip())
            current_chunk = section  # æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯é–‹å§‹
        else:
            current_chunk += "\n" + section  # ç¶™ç¶šã—ã¦è¿½åŠ 

    if current_chunk:  # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 
        chunks.append(current_chunk.strip())

    return chunks

def translate_gpt(ocr_response: OCRResponse, api_key_openai) -> str:
    """OCRã®Markdownãƒ†ã‚­ã‚¹ãƒˆã‚’è¦‹å‡ºã—ã”ã¨ã«ãƒãƒ£ãƒ³ã‚¯åŒ–ã—ã¦ç¿»è¨³ã—ã€ç”»åƒã‚’å†é…ç½®ã™ã‚‹"""

    client = OpenAI(api_key=api_key_openai)
    markdowns = []

    print(f"ğŸ“„ {len(ocr_response.pages)}ãƒšãƒ¼ã‚¸ã®ç¿»è¨³ã‚’é–‹å§‹ã—ã¾ã™...")

    for page_idx, page in enumerate(tqdm(ocr_response.pages, desc="ãƒšãƒ¼ã‚¸å‡¦ç†ä¸­", unit="page")):
        print(f"\nğŸ“ ãƒšãƒ¼ã‚¸ {page_idx + 1} / {len(ocr_response.pages)} ã‚’ç¿»è¨³ä¸­...")

        image_data = {img.id: img.image_base64 for img in page.images}  # ç”»åƒæƒ…å ±ã‚’è¾æ›¸ã«æ ¼ç´

        # ã‚¿ã‚¤ãƒˆãƒ«ãƒ»æœ¬æ–‡ãƒ»å‚è€ƒæ–‡çŒ®ã‚’åˆ†é›¢
        title, body, reference = split_title_and_reference(page.markdown)

        # æœ¬æ–‡ã‚’è¦‹å‡ºã—ã”ã¨ã«ãƒãƒ£ãƒ³ã‚¯åŒ–
        chunks = split_by_headings(body, max_tokens=8000)

        translated_chunks = []

        print(f"ğŸ”„ è¦‹å‡ºã—å˜ä½ã®ç¿»è¨³ï¼ˆ{len(chunks)} ãƒãƒ£ãƒ³ã‚¯ï¼‰...")

        # å„ãƒãƒ£ãƒ³ã‚¯ã‚’GPTã§ç¿»è¨³ï¼ˆé€²æ—ãƒãƒ¼è¡¨ç¤ºï¼‰
        for chunk_idx, chunk in enumerate(tqdm(chunks, desc=f"ãƒšãƒ¼ã‚¸ {page_idx + 1} ç¿»è¨³ä¸­", unit="chunk")):
            try:
                completion = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "å†…å®¹ã®è‹±èªã®æ–‡ç« ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®å½¢å¼ã‚’å´©ã•ãšã«æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"},
                        {"role": "user", "content": chunk},
                    ],
                )
                translated_chunks.append(completion.choices[0].message.content)
                print(f"âœ… ãƒãƒ£ãƒ³ã‚¯ {chunk_idx + 1} / {len(chunks)} ç¿»è¨³å®Œäº†")

            except Exception as e:
                print(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ {chunk_idx + 1} ã®ç¿»è¨³ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
                translated_chunks.append(chunk)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨

        # ç¿»è¨³å¾Œã®æœ¬æ–‡ã‚’å†çµåˆ
        translated_body = "\n".join(translated_chunks)

        # ã‚¿ã‚¤ãƒˆãƒ«ãƒ»ç¿»è¨³æ¸ˆã¿æœ¬æ–‡ãƒ»å‚è€ƒæ–‡çŒ®ã‚’å†æ§‹æˆ
        final_markdown = ""
        if title:
            final_markdown += title + "\n\n"
        final_markdown += translated_body + "\n\n"
        if reference:
            final_markdown += reference

        # ç”»åƒã‚’å…ƒã®ä½ç½®ã«æˆ»ã™
        final_markdown = replace_images_in_markdown(final_markdown, image_data)

        markdowns.append(final_markdown)

    print("\nğŸ‰ ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã®ç¿»è¨³ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    return "\n\n".join(markdowns)



if __name__ == "__main__":


    load_dotenv()  # .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

    api_key_mistralai = os.getenv("MISTRALAI_API_KEY")
    api_key_openai = os.getenv("OPENAI_API_KEY")

    # ãƒ­ãƒ¼ã‚«ãƒ«PDFã®ãƒ‘ã‚¹
    file_name = r"AttentionIsAllYouNeed.pdf"
    data_dir = f'data'
    
    ocr_response = ocr_pdf(api_key_mistralai, file_name, data_dir)

    paper_raw_md = get_combined_markdown(ocr_response)

    save_markdown(paper_raw_md, filename="output/test.md")
    
    paper_translated_md = translate_gpt(ocr_response, api_key_openai)

    save_markdown(paper_translated_md, filename="output/test_translated.md")


    